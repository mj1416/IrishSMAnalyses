\lhead{\emph{Forecasting Electric Load}}  % Set the left side page header to "Abbreviations"

\chapter{Electric Load Forecasts}
We reviewed many of the existing forecasting methods and techniques in section \ref{subsec:litrev} and we've discussed the value of having good forecasts with some commentary on how the quality of a forecast may be judged. In this chapter, various forecasts will be generated and their goodness discussed both qualitatively and quantitatively. Due to the strong periodic and symmetric autocorrelation (fig. \ref{fig:acf_day}), we can confidently use many of the common forecasting methods in the literature and build on those. Recall that we have 7 weeks of data, where we treat weeks 16-21 (inclusive) as past data and forecast week 22.

\section{Forecasts} \label{subsec:forecasts}

\subsection{Similar Day Forecast}

The first one considered here is the Similar Day (SD) method which forms the foundation of most electric load forecasting methods and is quite successful in itself as we'll see later. Therefore, we will use this forecast as the benchmark. The SD forecast is generated as follows:
\begin{enumerate}
\item The forecast at a given half hour for a specific day of the week is taken to be the arithmetic mean of all past observations which exist at the same half hour for the same day of the week. For example, the forecast for 9 am on Monday of week 22 (the last week in the 7 week data) will be the arithmetic mean of measurements taken at 9 am on Mondays of weeks 16 to 21.
\item This is repeated for each half hour for each day of the week for each household.
\item Thus a week long forecast is generated is at half hourly resolution.
\end{enumerate}

A sample forecast showing also the measured load for one customer is provided in figure \ref{fig:SDforecast}. From this, we can see that though the peaks are largely underestimated, they occur at roughly the right time, specifically the breakfast hours for the weekdays. Similarly, we see peak in forecast for the evening time, they are not underestimated but much more smooth than the observed load. This is because the timing for breakfast is more strictly constrained by jobs and other external deadlines. Additionally, it maybe argued that the underestimation of peaks is an effect of reduced load in the first weeks of the past data (recall fig. \ref{fig:sums}), though more realistically it is due to the smoothing effect from averaging.

\begin{figure}
\centering
\includegraphics[scale=0.5]{forecast_SD_P1.pdf}
\caption{SD forecast (for each day of the week) and the observations for customer 1.}
\label{fig:SDforecast} 
\end{figure}

\subsection{Last Week Forecast}

Another common but simple forecasting technique is the Last Week (LW) Forecast. It can be seen as a special case of the SD forecast where instead of using all historical data only the most recent week is used. Even before we test this method, it is probable that this is not a good forecasting method as relevant data, if available, may go unused and does not account for week to week variability. However, where data is not available, this may be the only option and in some cases may be a good enough option i.e for households which are very predictable.

As before, for the same customer, the LW forecast versus the observations are shown in figure \ref{fig:LW_forecast_P1}. It is clear that at least in the sample case LW is also not very well suited to representing the peaks accurately and is particularly vulnerable due to the week to week volatility in load. However, it can be seen that there are cases where, even though the magnitude of the peak is not correct, the peaks are being forecasted at roughly the right time. With this in mind we can combine the ideas from the SD and LW forecasts to generate an adjusted average forecast.

\begin{figure}
\includegraphics[scale=0.5]{forecast_LW_P1.pdf}
\caption{LW forecast (for each day of the week) for customer 1.}
\label{fig:LW_forecast_P1} 
\end{figure}

\subsection{Adjusted Average Forecast}

\cite{dan14} introduced an adjusted average (AA) forecast. The idea is that we start with a last week forecast and iteratively update it to included information from previous weeks with the most recent week having the most influence on the end forecast. The iterative update involved a local, restricted permutation in time which minimises some cost function. The algorithm as outlined by \cite{dan14} is as follows:

The forecast, as described by \cite{dan14}, forecasts each day of the week individually though analogously.
\begin{enumerate}[label=\roman*)]
\item Let $d$ be the day of the week being forecasted $(d=1,...,7)$ and suppose that there are $N$ daily usage profiles (i.e. historical data for day $d$ exists for the most recent $N$ weeks) at half hourly resolution. For $k = 1, ..., N$, the daily usage profile is denoted by $\boldsymbol{G}^{(k)} = (g_1^{(k)}, ... , g_{48}^{(k)})^T$. Note the convention that $\boldsymbol{G}^{(1)}$ is the profile for day $d$ in the most recent week whereas $\boldsymbol{G}^{(N)}$ is of the earliest week.
\item A base profile, $\boldsymbol{F}^{(1)} = \left(f_1^{(1)}, ... , f_{48}^{(1)} \right)^T$. Each $f_i^{(1)}$ is defined by the median of past load of the corresponding half hour i.e $ \forall \quad i \in (1, ..., 48), \quad f_i^{(1)} = \text{median}(g_i^{(1)}, ..., g_i^{(N)})$.
\item This baseline is updated iteratively to get the final forecast, $\boldsymbol{F}^{(N)}$, in the following way. Suppose, at iteration $k$, we have the $\boldsymbol{F}^{(k)}$ for $1 \le k \le N-1$, then $\boldsymbol{F}^{(k+1)}$ is obtained by setting $\boldsymbol{F}^{(k+1)} = \frac{1}{k+1} \left( \boldsymbol{\hat{G}}^{(k)} + k \boldsymbol{F}^{(k)}\right)$, where $\boldsymbol{\hat{G}}^{(k)} = \hat{P}\boldsymbol{G}^{(k)}$ with $\hat{P} \in  \mathscr{P}$ being a permutation matrix s.t. $||\hat{P}\boldsymbol{G}^{(k)} - \boldsymbol{F}^{(k)}||_4 = \displaystyle \min_{P \in \mathscr{P}}||P\boldsymbol{G}^{(k)} - \boldsymbol{F}^{(k)}||_4 $.
\item $\mathscr{P}$ is the set of restricted permutations i.e, for a chosen deformation limit $\omega$, the load at half hour $i$ can be moved to some half hour $j$ if $|i-j| \le \omega$. In \cite{dan14} and this report, $\omega=3$.
\item Thus one can see that the final forecast is given by $\boldsymbol{F}^{(N)} = \frac{1}{N+1}\left(\displaystyle \sum_{k=1}^n \boldsymbol{\hat{G}}^{(k)} + \boldsymbol{F}^{(1)} \right)$.
\end{enumerate}

The Hungarian algorithm is used to solve the minimisation problem above, which can be thought of as an optimisation problem. The Hungarian algorithm uses a cost matrix and thus for this implementation we must also specify a cost matrix. Recall that we have a deformation limit, $\omega$ which we set to 3. This comes into play as for any index $i = 1, ..., 48$, which relates to half hour, $(i,j)^{th}$ element is set to be the cost if $|i-j|\le\omega$ or set to be infinity if $|i-j| > \omega$. Thus at iteration $k$, the cost matrix looks like: \newline

\centerline{$\begin{bmatrix}
    |g_1^{(k)} - f_1^{(k)}| & |g_2^{(k)} - f_1^{(k)}| & |g_3^{(k)} - f_1^{(k)}| & |g_4^{(k)} -f_1^{(k)}| & \infty  & \infty& \infty & \infty & \dots & \infty \\
    |g_1^{(k)} - f_2^{(k)}| & |g_2^{(k)} - f_2^{(k)}| & |g_3^{(k)} - f_2^{(k)}| &  |g_4^{(k)} - f_2^{(k)}| & |g_5^{(k)} - f_2^{(k)}| & \infty & \infty &\infty & \dots & \infty\\
    |g_1^{(k)} - f_3^{(k)}| & |g_2^{(k)} - f_3^{(k)}| & |g_3^{(k)} - f_3^{(k)}| &  |g_4^{(k)} - f_3^{(k)}|& |g_5^{(k)}- f_3^{(k)}| & |g_6^{(k)}-f_3^{(k)}| & \infty & \infty & \dots  & \infty\\
    |g_1^{(k)}-f_4^{(k)}| & |g_2^{(k)} - f_4^{(k)}| & |g_3^{(k)} - f_4^{(k)}| & |g_4^{(k)} - f_4^{(k)}| &  |g_5^{(k)} - f_4^{(k)}| & |g_6^{(k)}- f_4^{(k)}|& |g_7^{(k)} - f_4^{(k)}| &\infty &\dots & \infty\\
    \infty & |g_2^{(k)} - f_5^{(k)}| & |g_3^{(k)} - f_5^{(k)}| & |g_4^{(k)} - f_5^{(k)}| &  |g_5^{(k)} - f_5^{(k)}|& |g_6^{(k)}- f_5^{(k)}|& |g_7^{(k)} - f_5^{(k)}| &|g_8^{(k)} - f_5^{(k)}| &\dots & \infty\\
     &  & \dots &  & &  & &  & \\
\end{bmatrix}$}

This algorithm is intuitively quite suited for forecasting as it gives a peaky forecast and at least for the sample forecast (fig. \ref{fig:AA_forecast_P1}) we can see that this is the case. Obviously not all peaks are represented well however from looking at this one customer, it seems that more peaks are being forecasted and roughly the correct times. The magnitudes are still not correct however in many cases they are closer to the observed than the SD forecast. We will quantify this further in section \ref{subsec:errs}. This should be the best forecast at least when the error measure used is the adjusted error measure.

\begin{figure}
\centering
\includegraphics[scale=0.5]{forecast_AA_P1.pdf}
\caption{AA forecast (for each day of the week) for customer 1 where the solid black line is the observed load, the broken black line is the SD forecast and broken blue line is the AA forecast.}
\label{fig:AA_forecast_P1} 
\end{figure}

\subsection{Weighted Average Forecast}

We can now move on to some other modifications of the SD forecast. The SD forecast weighted all past data equally and didn't use any window as in the AA forecast even though it is reasonable to think that a window of data from past weeks would be appropriate. Instead of guessing the weights we can calculate the weights using linear regression. As \cite{hong16} noted there is a misconception that linear regression can only be used in cases where there is a linear relationship between the independent and dependent variable. In fact linear regression is appropriate in applications where the model depends linearly on the unknown parameters, $\boldsymbol \beta$, (equation \ref{eq:lin_reg}) but the relationship between the features need not be linear.

Given a data set $\{y_i, x_{i1}, ... , x_{ip}\}_{i=1}^n$, linear regression, in vector form, can be represented as shown in equation \ref{eq:lin_reg}.

\begin{equation} \label{eq:lin_reg}
\textbf{y} = X \boldsymbol \beta +\boldsymbol \epsilon
\end{equation}
where $\textbf{y} = (y_1, y_2, ... , y_n)^T $, $X =  (\textbf{x}_1^T, \textbf{x}_2^T,, ... ,\textbf{x}_n^T)^T$,  $\textbf{x}_i^T, = (x_{i1}, ... , x_{ip})$ for $i = 1, ... , n$, $\boldsymbol \beta = (\beta_1 , ... , \beta_p)$ and $\boldsymbol \epsilon = (\epsilon_1, ... , \epsilon_n)$ and $( \cdot )^T$ denotes transpose. The $\boldsymbol \epsilon$ is a disturbance or error variable which adds noise to the model and is commonly assumed to be normally distributed with zero mean and variance $\sigma^2$.

Thus, in the context of electric load, we can use linear regression to predict each load at each half hour by modelling the relationship between the half hour in question and available observations that we deem relevant. We can inform ourselves of what is relevant by utilising the correlations (recall fig. \ref{fig:acf_day}). Thus by running 48 linear regressions, a one day forecast can be generated. The specifics of the implementation are as follows:
\begin{enumerate}
\item Using the python's SciKit package, linear regression is done on variable $X$ and $Y$, where $X$ is the matrix of features and $Y$ is the target variable.
%\item As mentioned before, the data set contains 7 weeks of data. These weeks range from 16 to 22. Week 22 is the week being forecasted and weeks 16 to 21 are considered "past" data which will form part of the feature matrix. 
\item The implementation contains two steps: \begin{enumerate} \item The first step is to find/learn the parameters $\boldsymbol \beta$. To do this both $X$ and $Y$ are required. In this first step, $Y$ is a vector which contains information about the half hour in question for each household for the most recent "past" week i.e week 21 whereas matrix $X$ contains data for the same half hour as well a lag 1 hour in each direction from weeks 16 to 20 (inclusive). Thus by using ordinary least squares, $\boldsymbol \beta$ is found by fitting $X$ to $Y$.
\item In the second step, the forecast is created. The python implementation requires the feature matrix in the fitting phase and the forecasting phase to have the same dimension thus $X$ has to be adjusted. Since we are now forecasting week 22, we use the same half hour and lags but are taken from weeks 17 to 21 to ensure that the new $X$ has the same dimensions as the old $X$. The values predicted by the model are the considered to be the forecast for the half hour in question for week 22. \end{enumerate}
\item The forecast that is produced using the above step is for the prescribed half hour of the prescribed day of the week. Thus, both the desired half hour and the day of the week are required inputs of the implementation.
\item The daily forecast for day $d$ is then produced by repeating the two steps for each half hour.
\item Then acquiring the weekly forecast, just means running the daily forecast for each day of the week.
\end{enumerate}

In this way it is possible to think of the SD forecast as a special case of the linear regression where the coefficients/parameters of the lag are zero in the SD forecast and the others are equal to 1 regardless of when measurements were made. This forecast will be referred to as the Weighted Average (WA) forecast, a sample of which along with the observations is shown in figure \ref{fig:LR_forecast_P1}. Given that many of the existing algorithms in the literature are some based around regression techniques, it is reasonable to expect that this is better than the LW forecast and also potentially the SD forecast given that it uses more data and the weights have been calculated rather than just given equal weighting. However, since the load profile is irregular, the peaks are likely to get smoothed in the process and may not be ideal for this context. This can explicitly be seen in figure in the sample forecasts given in figure \ref{fig:LR_forecast_P1} but we will quantify this more concretely as we proceed. %and \ref{fig:forecasts_P1}. 
\begin{figure}
\centering
\includegraphics[scale=0.5]{forecast_LR_P1.pdf}
\caption{Weighted Average forecast (for each day of the week) for customer 1.}
\label{fig:LR_forecast_P1} 
\end{figure}

\subsection{Bayesian Ridge Regression Forecast} % \label{subsubsec:BR}

Since we have an example of at least one paper \citep{douglas98} where the Bayesian framework has been applied, we can apply it too. Python's SciKit package provides an in built option with ridge regression, thus we call the following algorithm Bayesian Ridge Regression (BRR) forecast. Before looking at the results, let's look at the basic background of ridge regression. Ridge regression is the most common method of regularisation of ill-posed problems in statistics. A problem is said to be ill-posed if it has no solution or multiple solutions. Supposed we wish to find an $\boldsymbol{x}$ such that $A\boldsymbol{x}=\boldsymbol{b}$, where $A$ is a matrix and $\boldsymbol{x}$ and $\boldsymbol{b}$ are vectors. The ordinary least squares estimation solution would be a gained by a minimisation of $||A\boldsymbol{x} - \boldsymbol{b}||_2$ however for the ill-posed problem, this solution may be over-fitted or under-fitted. To give preference to a solution with desirable properties, the relgularisation term $||\Gamma\boldsymbol{x}||_2$ so that the minimisation is of $||A\boldsymbol{x} - \boldsymbol{b}||_2 + ||\Gamma\boldsymbol{x}||_2$, which gives the solution $\hat{\boldsymbol{x}} = \left(A^T A + \Gamma^T \Gamma \right)^{-1} A^T \boldsymbol{b}$. For the Bayesian interpretation,simplistically this regularised solution is the most probable solution given the data and the prior distribution for $\boldsymbol{x}$ according to Bayes' Theorem. The Python implementation is very much like the weighted average, where the coefficients are identified using the weeks 16 to 20 and the forecast for week 22 is generated using weeks 17 to 21.

Lastly we visualise a sample of BRR forecast along with the observations for one customer (fig. \ref{fig:BR_forecast_P1}). The forecast, at least for this customer, is qualitatively very similar to the WA forecast as we would expect very smooth and may thus be unsuitable for the context of load forecasts. It is also noteworthy that though this data set has no bank holidays and change of seasons, it does have a fundamental shift in behaviour due to schools opening half way through when measurements are taken. Perhaps these algorithms would be more successful if the forecasted week were also very similar to all the historical data being used to generate the forecast. We will quantitatively verify all the above forecasts in the next section.

\begin{figure}
\centering
\includegraphics[scale=0.5]{forecast_BR_P1.pdf}
\caption{Bayesian Ridge Regression forecast (for each day of the week) for customer 1.}
\label{fig:BR_forecast_P1} 
\end{figure}
\clearpage


\section{Forecast Validation} \label{subsec:errs}
As was discussed before in \ref{subsec:litrev}, there are many ways to judge a forecast. There is no absolute way of measuring the goodness of a forecast and depending on the error measure used, the conclusion may be qualitatively different (as will be seen later). Though there are no correct measures, some measures may be more appropriate or suitable than others for the application at hand. In this section we will consider two error measures, one which is quite commonly used and another which was developed by \cite{dan14} with electric load in mind.

The first one is the common $p-$norm error described in equation \ref{eq:err_p}, where $ p > 1 $.

\begin{equation}\label{eq:err_p}
E_p \equiv ||\boldsymbol{f} - \boldsymbol{a}||_p := \left( \sum_{i=1}^{n} |f_i - a_i |^p\right)^{\frac{1}{p}}
\end{equation}

where $\boldsymbol{f}$ is the forecast that is $n$ half hours long and $\boldsymbol{a}$ is the observed measurement. This gives the $p-$norm error for each household. Commonly, $p=2$ is taken, which translates to mean square root error however in this report we will take $p=4$ as has been done \citet{dan14} \todo{check this} so as to exaggerate larger differences. This was calculated for each household and is shown in figure \ref{fig:m4e_all}. The black line is the error at each household whereas the flat blue line is the average of all the households. These average has been tabulated in table \ref{tab:errs}.

\begin{figure}
\centering
\includegraphics[scale=0.5]{Errors_E_4.pdf}
\caption{\label{fig:m4e_all} $4^{th}$-norm error for each forecast.}
\end{figure}


The $4^{\textbf{th}}-$norm error provides a good benchmark for an error measure, however as was discussed before a point error metric such as this one falls prey to the double penalty effect. In order to reduce this effect we can do a restricted permutation locally in time by using the error measure introduced in \citet{dan14}. The mathematical set up for this error measure is as follows:
\begin{itemize}
\item $\hat{E}_p^\omega = \displaystyle{\min_{P \in \mathscr{P}}||P\textbf{f}-\textbf{x}||_p}$, where \textbf{f} is the forecast and \textbf{x} are the observations and where $\mathscr{P}$ represents the set of restricted permutations i.e. we allow the forecast to be matched to an observation within some window. The window was chosen to be 2 and a half hours, i.e. $\omega = 3$, as in \cite{dan14}. It should be noted that the value of $\omega$ need not be the same for the AA algorithm and the adjusted error measure.
\item The solution to above minimisation problem can be found using the Hungarian algorithm as for the AA forecast. The cost matrix for the error measure is then given as


\centerline{$\begin{bmatrix}
    |f_1 - x_1| & |f_2 - x_1| & |f_3 - x_1| & |f_4 - x_1|  & \infty& \infty& \infty &\infty & \dots & \infty \\
    |f_1 - x_2| & |f_2 - x_2| & |f_3 - x_2| &  |f_4 - x_2| & |f_5 - x_2| & \infty  &\infty & \infty & \dots & \infty\\
    |f_1 - x_3| & |f_2 - x_3| & |f_3 - x_3| &  |f_4 - x_3|& |f_5- x_3|& |f_6 - x_3| & \infty&\infty & \dots  & \infty\\
    |f_1 - x_4 & |f_2 - x_4| & |f_3 - x_4| & |f_4 - x_4| &  |f_5 - x_4|& |f_6- x_4|& |f_7 - x_4| & \infty&\dots & \infty\\
    \infty & |f_2 - x_5| & |f_3 - x_5| & |f_4 - x_5| &  |f_5 - x_5|& |f_6- x_5|& |f_7 - x_5| & |f_8 -x_5|&\dots & \infty\\
   &&&& \dots &&&&& \\
\end{bmatrix}$}

\noindent where we have chosen these values because the cost is the absolute difference between the forecast and observations.  
\item In this implementation, the above minimisation gives the adjusted error for each half hour for each household.
\end{itemize}

As for the $4^{\text{th}}-$norm error we can visualise the adjusted error but in order to this we must define the adjusted error for each household as $\hat{E}_4 := \left( \sum_{i=1}^{n} \hat{E}^4\right)^{\frac{1}{4}}$, where $n$ is the length of the forecast. As for the $4^{\text{th}}-$norm error, figure \ref{fig:Adj_err_all} shows the adjusted error for each household for each forecast in black with the flat blue line showing the average. These averages are also explicitly given in table \ref{tab:errs}

\begin{figure}
\centering
\includegraphics[scale=0.5]{Errors_Adj.pdf}
\caption{\label{fig:Adj_err_all} Adjusted error for each forecast.}
\end{figure}


\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
 & $E_4$ & $\hat{E}_e$ \\
 \hline
\textbf{SD} & 3.829 & 3.496 \\
\textbf{LW} & 4.76 & 4.100 \\ 
\textbf{AA} & 4.125 & 3.396 \\ 
\textbf{WA} & 3.866 & 3.542 \\ 
\textbf{BRR} & 3.805 & 3.575 \\
\hline
\end{tabular}
\caption{Mean of $4^{\text{th}}-$norm error and adjusted error.}
\label{tab:errs}
\end{table}


Table \ref{tab:errs} shows the value of the blue lines in each of forecasts using both error metrics. There are many disagreements both qualitatively and quantitatively but let's discuss the similarities first. In both cases, LW forecast is the worst method. This intuitively makes sense since we know LW forecast cannot take into account the week to week variability. While reasonable due to the smoothing effect, it is unexpected that both regression techniques are judged to be less accurate than the SD in either error measure. Note also that regardless of which error measure is used and which of the forecasts is being considered, the error has a range of roughly 3 kWh and 4 kWh. This is quite large considering that the $75^{\text{th}}$ percentile is around the 0.5 kWh.

From table \ref{tab:errs}, it is clear that the choice of metric alters not only the error value but also conclusion of which algorithm is the better. If the $4^{\text{th}}-$norm error metric is used, then the BRR forecast is the best and LW forecast is the worst with the AA forecast being judged the second worst but the same forecast is judged to be the best when the adjusted error measure is used. Based on the qualitative comparison in figures \ref{fig:SDforecast} - \ref{fig:BR_forecast_P1}, our understanding of forecasting electric load is better confirmed by the results from $\hat{E}_4$ and thus for the moment we will use the adjusted error measure to conclude which of the algorithms is better.






